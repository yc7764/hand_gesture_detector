{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os\n",
    "from matplotlib import pyplot as plt \n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False \n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results  \n",
    "    #손을 인식해서 좌표를 예측하는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image,results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    #이미지에 점을 그리는 메서드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic: \n",
    "    while cap.isOpened():\n",
    "    \n",
    "        ret, frame = cap.read()\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "    \n",
    "        #draw_landmarks(image,results)\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        if cv2.waitKey(10)&0xFF == ord('a'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()#메서드 사용해봤다~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, lh, rh]) #키포인트 추출하는 메서드 (예측하기 쉽게 데이터를 정리한거야)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('MP_Data') #학습데이터 저장하려고 파일경로 설정\n",
    "\n",
    "actions = np.array(['yes', 'no', 'hate',\"don't\",\"i'm fine\",'sorry',\"Let's go\",'do it','glad','good','bad','tired','follow you','follow me'])\n",
    "\n",
    "no_sequences = 50 \n",
    "\n",
    "sequence_length = 30 #한시퀀스에 30프레임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass\n",
    "        #파일경로를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    action = actions[13]\n",
    "    for sequence in range(no_sequences):\n",
    "        for frame_num in range(sequence_length):\n",
    "            ret, frame = cap.read()\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            draw_landmarks(image, results)\n",
    "                \n",
    "            if frame_num == 0:\n",
    "                cv2.putText(image, 'STARTING COLLECTION', (120,200),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Collection frames for {} video Number {}'.format(action, sequence), (15,12),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255),1,cv2.LINE_AA)\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                cv2.waitKey(2000)\n",
    "            else:\n",
    "                cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255),1,cv2.LINE_AA)\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "            keypoints = extract_keypoints(results)\n",
    "            npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "            np.save(npy_path, keypoints)\n",
    "                \n",
    "            if cv2.waitKey(10) & 0xFF == ord('a'):\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    #학습데이터 만드는중, 데이터가 배열형식으로 저장됐다... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': 0,\n",
       " 'no': 1,\n",
       " 'hate': 2,\n",
       " \"don't\": 3,\n",
       " \"i'm fine\": 4,\n",
       " 'sorry': 5,\n",
       " \"Let's go\": 6,\n",
       " 'do it': 7,\n",
       " 'glad': 8,\n",
       " 'good': 9,\n",
       " 'bad': 10,\n",
       " 'tired': 11,\n",
       " 'follow you': 12,\n",
       " 'follow me': 13}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map #딕셔너리형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "        #학습데이터 불러오고 레이블링- 문제의 답을 알려주는거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 30, 258)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape #인풋(문제)데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 30, 258)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]#Label과 신경망의 출력값을 비교하기 위해서 대응되도록 정수값 하나를 뉴런의 개수에 맞게 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,258))) #1.입력데이터와 입력층의 갯수를 맞춰줘야한다. \n",
    "#lstm 입력, 삭제, 출력게이트를 이용해서 셀상태 은닉상태를 계산한다.불필요한데이터지우고 오래 기억돼야할 데이터 정하는거\n",
    "#rnn 과 비교했을때 긴 시퀀스의 입력을 처리하는데 좋음. \n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))#마지막 레이어의 출력이 레이블이기때문에 (레이블이 모든 경우의수를 나타내기때문에)\n",
    "#2.출력층의 갯수와 레이블의 갯수를 맞춰줘야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 14s 219ms/step - loss: 2.6340 - categorical_accuracy: 0.1113\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 2.5271 - categorical_accuracy: 0.1534\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 2.2603 - categorical_accuracy: 0.1474\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 2.2369 - categorical_accuracy: 0.1880\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 2.0766 - categorical_accuracy: 0.1759\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 2.0559 - categorical_accuracy: 0.1789\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.9199 - categorical_accuracy: 0.1940\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 2.1263 - categorical_accuracy: 0.1684\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 2.0267 - categorical_accuracy: 0.1624\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 1.7938 - categorical_accuracy: 0.2180\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.7850 - categorical_accuracy: 0.2060\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.6804 - categorical_accuracy: 0.2782\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.5286 - categorical_accuracy: 0.3323\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.9158 - categorical_accuracy: 0.2451\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.9220 - categorical_accuracy: 0.2256\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.8429 - categorical_accuracy: 0.2271\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.6200 - categorical_accuracy: 0.2707\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 1.3911 - categorical_accuracy: 0.4030\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.2717 - categorical_accuracy: 0.4541\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 1.3005 - categorical_accuracy: 0.4632\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 1.3687 - categorical_accuracy: 0.3910\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 1.2821 - categorical_accuracy: 0.4226\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.2000 - categorical_accuracy: 0.4602\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.2355 - categorical_accuracy: 0.4586\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.0616 - categorical_accuracy: 0.5263\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.8233 - categorical_accuracy: 0.5368\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 2.0255 - categorical_accuracy: 0.2045\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 1.7772 - categorical_accuracy: 0.2180\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.5084 - categorical_accuracy: 0.3910\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.9374 - categorical_accuracy: 0.2406\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 1.7656 - categorical_accuracy: 0.2917\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.4342 - categorical_accuracy: 0.4271\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.5912 - categorical_accuracy: 0.3699\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.5587 - categorical_accuracy: 0.3368\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.4712 - categorical_accuracy: 0.3805\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.4704 - categorical_accuracy: 0.3805\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 1.2023 - categorical_accuracy: 0.5173\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.1935 - categorical_accuracy: 0.5338\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 2.4564 - categorical_accuracy: 0.2211\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 2.5468 - categorical_accuracy: 0.0827\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 2.0609 - categorical_accuracy: 0.2226\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.6917 - categorical_accuracy: 0.3398\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 1.4497 - categorical_accuracy: 0.3850\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.2898 - categorical_accuracy: 0.4436\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.1202 - categorical_accuracy: 0.5519\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.1281 - categorical_accuracy: 0.5459\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.9645 - categorical_accuracy: 0.5910\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.0584 - categorical_accuracy: 0.5744\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.8953 - categorical_accuracy: 0.3744\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 2.2845 - categorical_accuracy: 0.1774\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 2.0682 - categorical_accuracy: 0.2361\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 1.9581 - categorical_accuracy: 0.2211\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.8681 - categorical_accuracy: 0.2376\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.7255 - categorical_accuracy: 0.3323\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 1.6933 - categorical_accuracy: 0.3609\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 1.4188 - categorical_accuracy: 0.4842\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.0777 - categorical_accuracy: 0.6451\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.7922 - categorical_accuracy: 0.7383\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 1.0266 - categorical_accuracy: 0.5774\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.7921 - categorical_accuracy: 0.6902\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.6854 - categorical_accuracy: 0.7158\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 0.4960 - categorical_accuracy: 0.8120\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.7053 - categorical_accuracy: 0.6947\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.7677 - categorical_accuracy: 0.6797\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 0.5034 - categorical_accuracy: 0.7970\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 0.3922 - categorical_accuracy: 0.8451\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.6973 - categorical_accuracy: 0.7323\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 0.5417 - categorical_accuracy: 0.7624\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 0.3819 - categorical_accuracy: 0.8556\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.3963 - categorical_accuracy: 0.8391\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.4057 - categorical_accuracy: 0.8211\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 3s 136ms/step - loss: 0.5958 - categorical_accuracy: 0.7699\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.5605 - categorical_accuracy: 0.7639\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 0.4067 - categorical_accuracy: 0.8496\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.3531 - categorical_accuracy: 0.8647\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.3351 - categorical_accuracy: 0.8737\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.3117 - categorical_accuracy: 0.8737\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 0.2998 - categorical_accuracy: 0.8977\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 0.2814 - categorical_accuracy: 0.8962\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 0.2605 - categorical_accuracy: 0.9083\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.2989 - categorical_accuracy: 0.8947\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 0.6558 - categorical_accuracy: 0.7444\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 0.4478 - categorical_accuracy: 0.8301\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 0.2895 - categorical_accuracy: 0.8917\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.2348 - categorical_accuracy: 0.9203\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.2453 - categorical_accuracy: 0.9023\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.2535 - categorical_accuracy: 0.9113\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.2853 - categorical_accuracy: 0.9008\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.2672 - categorical_accuracy: 0.9038\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.2293 - categorical_accuracy: 0.9188\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 3s 138ms/step - loss: 0.3846 - categorical_accuracy: 0.8647\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.4523 - categorical_accuracy: 0.8180\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.2590 - categorical_accuracy: 0.9083\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 0.2409 - categorical_accuracy: 0.9233\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 0.2058 - categorical_accuracy: 0.9338\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 0.2707 - categorical_accuracy: 0.9023\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 3s 122ms/step - loss: 0.2421 - categorical_accuracy: 0.9128\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 3s 120ms/step - loss: 0.2254 - categorical_accuracy: 0.9143\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.2559 - categorical_accuracy: 0.9113\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 3s 136ms/step - loss: 0.1967 - categorical_accuracy: 0.9218\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.1576 - categorical_accuracy: 0.9414\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 264s 13s/step - loss: 0.1874 - categorical_accuracy: 0.9414\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 2s 113ms/step - loss: 0.1564 - categorical_accuracy: 0.9534\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 2s 118ms/step - loss: 0.2013 - categorical_accuracy: 0.9308\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 1.2692 - categorical_accuracy: 0.6677\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.9731 - categorical_accuracy: 0.6496\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 0.6514 - categorical_accuracy: 0.7624\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 0.5057 - categorical_accuracy: 0.7774\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.4424 - categorical_accuracy: 0.7865\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.3380 - categorical_accuracy: 0.8692\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.2490 - categorical_accuracy: 0.9083\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.2675 - categorical_accuracy: 0.9053\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.3626 - categorical_accuracy: 0.8722\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.3083 - categorical_accuracy: 0.8872\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.2776 - categorical_accuracy: 0.8947\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.2049 - categorical_accuracy: 0.9308\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.1792 - categorical_accuracy: 0.9353\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1993 - categorical_accuracy: 0.9338\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 0.1758 - categorical_accuracy: 0.9504\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.1983 - categorical_accuracy: 0.9278\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.2194 - categorical_accuracy: 0.9158\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.2057 - categorical_accuracy: 0.9278\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.1906 - categorical_accuracy: 0.9308\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 0.2100 - categorical_accuracy: 0.9143\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.1583 - categorical_accuracy: 0.9489\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.1373 - categorical_accuracy: 0.9534\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 0.1544 - categorical_accuracy: 0.9383\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 4s 183ms/step - loss: 0.1893 - categorical_accuracy: 0.9398\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 4s 183ms/step - loss: 0.6103 - categorical_accuracy: 0.86471s - loss: 0.1822 - categorica\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 4s 183ms/step - loss: 2.0728 - categorical_accuracy: 0.3970\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 4s 183ms/step - loss: 1.2756 - categorical_accuracy: 0.4737\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 4s 183ms/step - loss: 0.9378 - categorical_accuracy: 0.6902\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 4s 183ms/step - loss: 0.6477 - categorical_accuracy: 0.75192s - loss: 0.6\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 4s 183ms/step - loss: 0.4015 - categorical_accuracy: 0.8842\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 4s 183ms/step - loss: 0.5092 - categorical_accuracy: 0.8180\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 4s 182ms/step - loss: 0.3775 - categorical_accuracy: 0.8421\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 4s 184ms/step - loss: 0.2796 - categorical_accuracy: 0.9248\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 4s 184ms/step - loss: 0.1858 - categorical_accuracy: 0.9444\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 3s 139ms/step - loss: 0.1547 - categorical_accuracy: 0.9534\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.2701 - categorical_accuracy: 0.9083\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 0.4925 - categorical_accuracy: 0.8421\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 4s 182ms/step - loss: 0.2547 - categorical_accuracy: 0.9248\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 180ms/step - loss: 0.1702 - categorical_accuracy: 0.9489\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 0.1320 - categorical_accuracy: 0.9639\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 0.1590 - categorical_accuracy: 0.9398\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.4642 - categorical_accuracy: 0.8647\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.5331 - categorical_accuracy: 0.7925\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.2715 - categorical_accuracy: 0.9203\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.1983 - categorical_accuracy: 0.9444\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.1435 - categorical_accuracy: 0.9534\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.2105 - categorical_accuracy: 0.9203\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1776 - categorical_accuracy: 0.9353\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1729 - categorical_accuracy: 0.9444\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1824 - categorical_accuracy: 0.9414\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1493 - categorical_accuracy: 0.9504\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.1995 - categorical_accuracy: 0.9368\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1992 - categorical_accuracy: 0.9278\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1213 - categorical_accuracy: 0.9594\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.1246 - categorical_accuracy: 0.9549\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1296 - categorical_accuracy: 0.9549\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1345 - categorical_accuracy: 0.9444\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.0961 - categorical_accuracy: 0.9699\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.0929 - categorical_accuracy: 0.9699\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 0.0921 - categorical_accuracy: 0.9669\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.0938 - categorical_accuracy: 0.9684\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.0776 - categorical_accuracy: 0.9714\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 3s 134ms/step - loss: 0.1160 - categorical_accuracy: 0.9594\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.8333 - categorical_accuracy: 0.7865\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.3493 - categorical_accuracy: 0.8677\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 0.1906 - categorical_accuracy: 0.9353\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.1091 - categorical_accuracy: 0.9714\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.0739 - categorical_accuracy: 0.9805\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.0761 - categorical_accuracy: 0.9714\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.1052 - categorical_accuracy: 0.9639\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 0.0953 - categorical_accuracy: 0.9714\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1086 - categorical_accuracy: 0.9639\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.0530 - categorical_accuracy: 0.9820\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 0.0981 - categorical_accuracy: 0.9669\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.0654 - categorical_accuracy: 0.9774\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.1585 - categorical_accuracy: 0.9398\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.0941 - categorical_accuracy: 0.9549\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.5418 - categorical_accuracy: 0.8812\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.4834 - categorical_accuracy: 0.8406\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.1751 - categorical_accuracy: 0.9414\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.1017 - categorical_accuracy: 0.9714\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 3s 122ms/step - loss: 0.0918 - categorical_accuracy: 0.9805\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 0.0690 - categorical_accuracy: 0.9835\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.0695 - categorical_accuracy: 0.9820\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.0735 - categorical_accuracy: 0.9699\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.1291 - categorical_accuracy: 0.9579\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.0985 - categorical_accuracy: 0.9579\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.0819 - categorical_accuracy: 0.9759\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.0525 - categorical_accuracy: 0.9835\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 0.0714 - categorical_accuracy: 0.9699\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 3s 128ms/step - loss: 0.2077 - categorical_accuracy: 0.9158\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 3s 122ms/step - loss: 0.1852 - categorical_accuracy: 0.9263\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.0862 - categorical_accuracy: 0.9669\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.0939 - categorical_accuracy: 0.9684\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 0.0616 - categorical_accuracy: 0.9789\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.0810 - categorical_accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=200, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do it'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do it'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4979230e-04, 5.7187481e-07, 1.5276859e-05, 2.9834076e-03,\n",
       "       2.4532428e-05, 3.5762271e-09, 3.0127123e-05, 9.9664491e-01,\n",
       "       2.0850991e-06, 1.3881223e-14, 8.8510051e-14, 4.9232116e-05,\n",
       "       5.3439982e-11, 2.9082910e-12], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[613,   4],\n",
       "        [ 12,  36]],\n",
       "\n",
       "       [[623,   0],\n",
       "        [  1,  41]],\n",
       "\n",
       "       [[603,  12],\n",
       "        [ 10,  40]],\n",
       "\n",
       "       [[617,   0],\n",
       "        [  0,  48]],\n",
       "\n",
       "       [[607,  12],\n",
       "        [  6,  40]],\n",
       "\n",
       "       [[615,   0],\n",
       "        [  2,  48]],\n",
       "\n",
       "       [[615,   3],\n",
       "        [  0,  47]],\n",
       "\n",
       "       [[619,   0],\n",
       "        [  6,  40]],\n",
       "\n",
       "       [[615,   1],\n",
       "        [  0,  49]],\n",
       "\n",
       "       [[613,   4],\n",
       "        [  0,  48]],\n",
       "\n",
       "       [[616,   1],\n",
       "        [  1,  47]],\n",
       "\n",
       "       [[618,   0],\n",
       "        [  1,  46]],\n",
       "\n",
       "       [[617,   0],\n",
       "        [  0,  48]],\n",
       "\n",
       "       [[615,   2],\n",
       "        [  0,  48]]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9413533834586466"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tired\n",
      "yes\n",
      "do it\n",
      "yes\n",
      "tired\n",
      "bad\n",
      "don't\n",
      "i'm fine\n",
      "don't\n",
      "good\n",
      "i'm fine\n",
      "Let's go\n",
      "do it\n",
      "hate\n",
      "don't\n",
      "i'm fine\n",
      "do it\n",
      "hate\n",
      "do it\n",
      "hate\n",
      "do it\n",
      "hate\n",
      "don't\n",
      "i'm fine\n",
      "do it\n",
      "hate\n",
      "i'm fine\n",
      "don't\n",
      "bad\n",
      "good\n",
      "Let's go\n",
      "do it\n",
      "i'm fine\n",
      "don't\n",
      "good\n",
      "Let's go\n",
      "good\n",
      "Let's go\n",
      "i'm fine\n",
      "good\n",
      "i'm fine\n",
      "Let's go\n",
      "good\n",
      "Let's go\n",
      "good\n",
      "i'm fine\n",
      "good\n",
      "follow you\n",
      "glad\n",
      "no\n",
      "follow me\n",
      "no\n",
      "Let's go\n",
      "good\n",
      "follow you\n",
      "glad\n",
      "no\n",
      "follow me\n",
      "no\n",
      "Let's go\n",
      "good\n",
      "Let's go\n",
      "follow me\n",
      "sorry\n",
      "do it\n",
      "hate\n",
      "don't\n",
      "bad\n",
      "follow you\n",
      "Let's go\n",
      "good\n",
      "Let's go\n",
      "follow me\n",
      "do it\n",
      "i'm fine\n",
      "good\n",
      "don't\n",
      "bad\n",
      "follow you\n",
      "no\n",
      "glad\n",
      "follow you\n",
      "glad\n",
      "no\n",
      "Let's go\n",
      "follow you\n",
      "Let's go\n",
      "no\n",
      "glad\n",
      "follow you\n",
      "glad\n",
      "no\n",
      "glad\n",
      "no\n",
      "glad\n",
      "no\n",
      "follow me\n",
      "sorry\n",
      "do it\n",
      "yes\n",
      "tired\n",
      "bad\n",
      "follow you\n",
      "glad\n",
      "sorry\n",
      "glad\n",
      "no\n",
      "glad\n",
      "follow you\n",
      "glad\n",
      "no\n",
      "follow me\n",
      "Let's go\n",
      "i'm fine\n",
      "good\n",
      "bad\n",
      "follow you\n",
      "glad\n",
      "sorry\n",
      "glad\n",
      "no\n",
      "glad\n",
      "no\n",
      "follow me\n",
      "sorry\n",
      "do it\n",
      "hate\n",
      "do it\n",
      "hate\n",
      "don't\n",
      "hate\n",
      "do it\n",
      "hate\n",
      "do it\n",
      "yes\n",
      "hate\n",
      "tired\n",
      "don't\n",
      "good\n",
      "i'm fine\n",
      "do it\n",
      "i'm fine\n",
      "hate\n",
      "i'm fine\n",
      "do it\n",
      "hate\n",
      "i'm fine\n",
      "hate\n",
      "i'm fine\n",
      "hate\n",
      "do it\n"
     ]
    }
   ],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.4\n",
    "tmp = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        draw_landmarks(image, results)\n",
    "        \n",
    "        keypoints = extract_keypoints(results)\n",
    "        #sequence.append(keypoints)\n",
    "        sequence.insert(0,keypoints)\n",
    "        sequence = sequence[:30]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            if tmp != np.argmax(res):\n",
    "                tmp = np.argmax(res)\n",
    "                print(actions[np.argmax(res)])\n",
    "            \n",
    "        #if res[np.argmax(res)] > threshold:\n",
    "         #   if len(sentence) > 0:\n",
    "          #      if actions[np.argmax(res)] != sentence[-1]:\n",
    "           #         sentence.append(actions[np.argmax(res)])\n",
    "           # else:\n",
    "            #    sentence.append(actions[0])\n",
    "        \n",
    "       # if len(sentence) > 5:\n",
    "        #    sentence = sentence[-5:]\n",
    "        \n",
    "        #cv2.rectangle(image, (0,0),(640,40), (245,117,16), -1)\n",
    "        #cv2.putText(image, ''.join(sentence), (3,30),\n",
    "        #                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
